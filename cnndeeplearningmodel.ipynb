{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleynasancakli/Global-AI-Hub-Deep-Learning-Bootcamp-Project/blob/main/cnndeeplearningmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerekli kütüphaneleri indirme;"
      ],
      "metadata": {
        "id": "m16trJh1muQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "\n",
        "from glob import glob # allows us to read multiple files in a directory. \n",
        "\n",
        "# Ses işleme için (Fakat hazır spectogramları kullandığımız için librosa'ya ihtiyaç duymadık)\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Görüntü işlemek için\n",
        "import cv2 \n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#  for interacting with the operating system\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, minmax_scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play some of the audios\n",
        "import IPython.display as ipd\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "PIeobuvTmv11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab'i Google Drive'a bağlama"
      ],
      "metadata": {
        "id": "ZIeBLZ8YmH01"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fscF-EcmCwl",
        "outputId": "99691b18-f596-4b97-9b7d-f7746d8f989f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Datasets"
      ],
      "metadata": {
        "id": "eb6tO9eFmN_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_link = \"/content/drive/MyDrive/datasets\"\n",
        "X_train = pickle.load(open(f\"{pickle_file_link}/X_train.pickle\", \"rb\"))\n",
        "y_train = pickle.load(open(f\"{pickle_file_link}/y_train.pickle\", \"rb\"))\n",
        "\n",
        "X_val = pickle.load(open(f\"{pickle_file_link}/X_val.pickle\", \"rb\"))\n",
        "y_val = pickle.load(open(f\"{pickle_file_link}/y_val.pickle\", \"rb\"))\n",
        "\n",
        "X_test = pickle.load(open(f\"{pickle_file_link}/X_test.pickle\", \"rb\"))\n",
        "y_test = pickle.load(open(f\"{pickle_file_link}/y_test.pickle\", \"rb\"))"
      ],
      "metadata": {
        "id": "BCsUoZF1mTH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating CNN Model"
      ],
      "metadata": {
        "id": "BQtRxcvamfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
        "from keras import Sequential\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', \n",
        "                 input_shape = (128,128,1)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters = 256 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7CUj3pemjr8",
        "outputId": "eb98ae0f-48f8-4724-b305-9020ea66b2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 64)      1664      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 64)      102464    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 128)       204928    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 128)       409728    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         819456    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                163850    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,702,090\n",
            "Trainable params: 1,702,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "eccyMI73nAFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "ukqWBx48taHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model for 50 epochs "
      ],
      "metadata": {
        "id": "3yjHCqvvtdAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainn = np.array(X_train)\n",
        "y_trainn = np.array(y_train)\n",
        "X_testt = np.array(X_test)\n",
        "y_testt = np.array(y_test)\n",
        "X_vall = np.array(X_val)\n",
        "y_vall = np.array(y_val)\n",
        "\n",
        "results = model.fit(X_trainn, y_trainn, batch_size = 128, epochs=50, validation_data = (X_vall, y_vall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkPt7m8Jtxqq",
        "outputId": "eea22ded-2277-4b24-8434-c2cf85a3761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 29s 300ms/step - loss: 1.7109 - accuracy: 0.3808 - val_loss: 1.4736 - val_accuracy: 0.4950\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 1.1615 - accuracy: 0.6038 - val_loss: 1.0781 - val_accuracy: 0.6737\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.8633 - accuracy: 0.7119 - val_loss: 0.7827 - val_accuracy: 0.7507\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.6754 - accuracy: 0.7722 - val_loss: 0.7017 - val_accuracy: 0.7644\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.5572 - accuracy: 0.8180 - val_loss: 0.7558 - val_accuracy: 0.7360\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.4648 - accuracy: 0.8455 - val_loss: 0.4620 - val_accuracy: 0.8570\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.3777 - accuracy: 0.8757 - val_loss: 0.4695 - val_accuracy: 0.8579\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.3076 - accuracy: 0.8948 - val_loss: 0.3657 - val_accuracy: 0.8882\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.2647 - accuracy: 0.9091 - val_loss: 0.3209 - val_accuracy: 0.8918\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.2371 - accuracy: 0.9195 - val_loss: 0.4330 - val_accuracy: 0.8781\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.2068 - accuracy: 0.9307 - val_loss: 0.4445 - val_accuracy: 0.8625\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1962 - accuracy: 0.9321 - val_loss: 0.3505 - val_accuracy: 0.8891\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1717 - accuracy: 0.9398 - val_loss: 0.3066 - val_accuracy: 0.9184\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1362 - accuracy: 0.9525 - val_loss: 0.2531 - val_accuracy: 0.9322\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1346 - accuracy: 0.9556 - val_loss: 0.2811 - val_accuracy: 0.9193\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1418 - accuracy: 0.9510 - val_loss: 0.2901 - val_accuracy: 0.9212\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.1288 - accuracy: 0.9548 - val_loss: 0.3216 - val_accuracy: 0.9111\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1118 - accuracy: 0.9620 - val_loss: 0.2871 - val_accuracy: 0.9193\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.1088 - accuracy: 0.9649 - val_loss: 0.2557 - val_accuracy: 0.9267\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0918 - accuracy: 0.9698 - val_loss: 0.2729 - val_accuracy: 0.9248\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0716 - accuracy: 0.9780 - val_loss: 0.3118 - val_accuracy: 0.9248\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.2984 - val_accuracy: 0.9276\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0890 - accuracy: 0.9713 - val_loss: 0.3257 - val_accuracy: 0.9294\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.3226 - val_accuracy: 0.9175\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1301 - accuracy: 0.9603 - val_loss: 0.2232 - val_accuracy: 0.9395\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 0.2775 - val_accuracy: 0.9303\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.3103 - val_accuracy: 0.9358\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0599 - accuracy: 0.9795 - val_loss: 0.3632 - val_accuracy: 0.9221\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0729 - accuracy: 0.9765 - val_loss: 0.2720 - val_accuracy: 0.9303\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 13s 260ms/step - loss: 0.0618 - accuracy: 0.9805 - val_loss: 0.2669 - val_accuracy: 0.9349\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 0.0574 - accuracy: 0.9808 - val_loss: 0.3013 - val_accuracy: 0.9331\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0676 - accuracy: 0.9803 - val_loss: 0.3300 - val_accuracy: 0.9267\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0691 - accuracy: 0.9777 - val_loss: 0.2657 - val_accuracy: 0.9413\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0688 - accuracy: 0.9779 - val_loss: 0.3127 - val_accuracy: 0.9267\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 0.3339 - val_accuracy: 0.9258\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0541 - accuracy: 0.9824 - val_loss: 0.2976 - val_accuracy: 0.9313\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.3646 - val_accuracy: 0.9184\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0613 - accuracy: 0.9837 - val_loss: 0.2905 - val_accuracy: 0.9377\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.2960 - val_accuracy: 0.9313\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.3461 - val_accuracy: 0.9239\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0564 - accuracy: 0.9818 - val_loss: 0.2905 - val_accuracy: 0.9258\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0583 - accuracy: 0.9831 - val_loss: 0.3302 - val_accuracy: 0.9239\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0634 - accuracy: 0.9798 - val_loss: 0.2747 - val_accuracy: 0.9395\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0716 - accuracy: 0.9769 - val_loss: 0.2593 - val_accuracy: 0.9377\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.2760 - val_accuracy: 0.9450\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.3034 - val_accuracy: 0.9377\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0690 - accuracy: 0.9777 - val_loss: 0.2829 - val_accuracy: 0.9349\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0581 - accuracy: 0.9794 - val_loss: 0.2941 - val_accuracy: 0.9459\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.2693 - val_accuracy: 0.9358\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.2787 - val_accuracy: 0.9413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the the training loss and accuracy\n"
      ],
      "metadata": {
        "id": "x3RUfTITts7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(121)\n",
        "plt.plot(results.history[\"loss\"], label = \"Train\")\n",
        "plt.plot(results.history[\"val_loss\"], label = \"Test\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(results.history[\"accuracy\"], label = \"Train\")\n",
        "plt.plot(results.history[\"val_accuracy\"], label= \"Test\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qiptYZOmuDzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "178cde01-7edd-4f2c-f5bd-ae300f363803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the performance"
      ],
      "metadata": {
        "id": "2Cn575VUuoZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = model.test_on_batch(X_testt, y_testt)\n",
        "\n",
        "# Print the result [loss, accuracy]\n",
        "print(f\"Loss: {test_result[0]}, Accuracy: {test_result[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBQo_xPtnAyt",
        "outputId": "28cba125-8819-4003-8e7c-a08dace3e1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.27935492992401123, Accuracy: 0.9349817037582397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H2-vimeWqs4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Optimization\n"
      ],
      "metadata": {
        "id": "ylMx8uBaC7b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dropout(0.5))\n",
        "\n",
        "results = model.fit(X_trainn, y_trainn, batch_size = 64, epochs=100, validation_data = (X_vall, y_vall))\n",
        "test_result = model.test_on_batch(X_testt, y_testt)\n",
        "\n",
        "# Print the result [loss, accuracy]\n",
        "print(f\"Loss: {test_result[0]}, Accuracy: {test_result[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozXRlQBuHHjv",
        "outputId": "85d24730-5156-4fd0-fa6a-88fcbd1eca78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "103/103 [==============================] - 16s 134ms/step - loss: 0.1193 - accuracy: 0.9640 - val_loss: 0.3799 - val_accuracy: 0.9157\n",
            "Epoch 2/100\n",
            "103/103 [==============================] - 13s 130ms/step - loss: 0.1353 - accuracy: 0.9568 - val_loss: 0.3097 - val_accuracy: 0.9248\n",
            "Epoch 3/100\n",
            "103/103 [==============================] - 13s 130ms/step - loss: 0.1349 - accuracy: 0.9545 - val_loss: 0.2754 - val_accuracy: 0.9212\n",
            "Epoch 4/100\n",
            "103/103 [==============================] - 13s 131ms/step - loss: 0.1214 - accuracy: 0.9656 - val_loss: 0.3126 - val_accuracy: 0.9248\n",
            "Epoch 5/100\n",
            "103/103 [==============================] - 14s 131ms/step - loss: 0.0983 - accuracy: 0.9689 - val_loss: 0.3647 - val_accuracy: 0.9093\n",
            "Epoch 6/100\n",
            "103/103 [==============================] - 14s 131ms/step - loss: 0.0966 - accuracy: 0.9707 - val_loss: 0.2841 - val_accuracy: 0.9303\n",
            "Epoch 7/100\n",
            "103/103 [==============================] - 14s 131ms/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 0.2662 - val_accuracy: 0.9441\n",
            "Epoch 8/100\n",
            "103/103 [==============================] - 14s 131ms/step - loss: 0.0902 - accuracy: 0.9736 - val_loss: 0.2358 - val_accuracy: 0.9413\n",
            "Epoch 9/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0660 - accuracy: 0.9808 - val_loss: 0.2765 - val_accuracy: 0.9349\n",
            "Epoch 10/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0595 - accuracy: 0.9835 - val_loss: 0.3258 - val_accuracy: 0.9303\n",
            "Epoch 11/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 0.2769 - val_accuracy: 0.9441\n",
            "Epoch 12/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.2884 - val_accuracy: 0.9368\n",
            "Epoch 13/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0996 - accuracy: 0.9728 - val_loss: 0.4406 - val_accuracy: 0.8973\n",
            "Epoch 14/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0943 - accuracy: 0.9730 - val_loss: 0.2433 - val_accuracy: 0.9358\n",
            "Epoch 15/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0726 - accuracy: 0.9789 - val_loss: 0.3029 - val_accuracy: 0.9221\n",
            "Epoch 16/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 0.2676 - val_accuracy: 0.9358\n",
            "Epoch 17/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0593 - accuracy: 0.9817 - val_loss: 0.3662 - val_accuracy: 0.9267\n",
            "Epoch 18/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0569 - accuracy: 0.9820 - val_loss: 0.4006 - val_accuracy: 0.9175\n",
            "Epoch 19/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0715 - accuracy: 0.9803 - val_loss: 0.3469 - val_accuracy: 0.9331\n",
            "Epoch 20/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.3415 - val_accuracy: 0.9239\n",
            "Epoch 21/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0988 - accuracy: 0.9750 - val_loss: 0.2876 - val_accuracy: 0.9340\n",
            "Epoch 22/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.2450 - val_accuracy: 0.9459\n",
            "Epoch 23/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.2961 - val_accuracy: 0.9248\n",
            "Epoch 24/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.2317 - val_accuracy: 0.9413\n",
            "Epoch 25/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.2441 - val_accuracy: 0.9505\n",
            "Epoch 26/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 0.2927 - val_accuracy: 0.9413\n",
            "Epoch 27/100\n",
            "103/103 [==============================] - 14s 137ms/step - loss: 0.0595 - accuracy: 0.9829 - val_loss: 0.2991 - val_accuracy: 0.9386\n",
            "Epoch 28/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.1062 - accuracy: 0.9705 - val_loss: 0.4150 - val_accuracy: 0.9157\n",
            "Epoch 29/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0869 - accuracy: 0.9768 - val_loss: 0.3321 - val_accuracy: 0.9276\n",
            "Epoch 30/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0697 - accuracy: 0.9803 - val_loss: 0.2478 - val_accuracy: 0.9413\n",
            "Epoch 31/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.3086 - val_accuracy: 0.9395\n",
            "Epoch 32/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0469 - accuracy: 0.9870 - val_loss: 0.2822 - val_accuracy: 0.9450\n",
            "Epoch 33/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.2963 - val_accuracy: 0.9358\n",
            "Epoch 34/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.4242 - val_accuracy: 0.9239\n",
            "Epoch 35/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.3473 - val_accuracy: 0.9331\n",
            "Epoch 36/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0553 - accuracy: 0.9855 - val_loss: 0.2769 - val_accuracy: 0.9322\n",
            "Epoch 37/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.3041 - val_accuracy: 0.9368\n",
            "Epoch 38/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.3410 - val_accuracy: 0.9413\n",
            "Epoch 39/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 0.3983 - val_accuracy: 0.9248\n",
            "Epoch 40/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0616 - accuracy: 0.9824 - val_loss: 0.2755 - val_accuracy: 0.9395\n",
            "Epoch 41/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0714 - accuracy: 0.9794 - val_loss: 0.4400 - val_accuracy: 0.9239\n",
            "Epoch 42/100\n",
            "103/103 [==============================] - 14s 137ms/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.2991 - val_accuracy: 0.9386\n",
            "Epoch 43/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.2702 - val_accuracy: 0.9340\n",
            "Epoch 44/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.3164 - val_accuracy: 0.9276\n",
            "Epoch 45/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.2714 - val_accuracy: 0.9331\n",
            "Epoch 46/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0428 - accuracy: 0.9873 - val_loss: 0.2870 - val_accuracy: 0.9386\n",
            "Epoch 47/100\n",
            "103/103 [==============================] - 14s 138ms/step - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.4017 - val_accuracy: 0.9276\n",
            "Epoch 48/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0590 - accuracy: 0.9849 - val_loss: 0.4274 - val_accuracy: 0.9294\n",
            "Epoch 49/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0918 - accuracy: 0.9766 - val_loss: 0.2774 - val_accuracy: 0.9322\n",
            "Epoch 50/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0600 - accuracy: 0.9823 - val_loss: 0.3473 - val_accuracy: 0.9294\n",
            "Epoch 51/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0495 - accuracy: 0.9876 - val_loss: 0.2962 - val_accuracy: 0.9285\n",
            "Epoch 52/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.3909 - val_accuracy: 0.9221\n",
            "Epoch 53/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0575 - accuracy: 0.9864 - val_loss: 0.3315 - val_accuracy: 0.9423\n",
            "Epoch 54/100\n",
            "103/103 [==============================] - 14s 138ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.3719 - val_accuracy: 0.9368\n",
            "Epoch 55/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.3882 - val_accuracy: 0.9267\n",
            "Epoch 56/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0620 - accuracy: 0.9856 - val_loss: 0.3843 - val_accuracy: 0.9313\n",
            "Epoch 57/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0605 - accuracy: 0.9846 - val_loss: 0.3433 - val_accuracy: 0.9386\n",
            "Epoch 58/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 0.3434 - val_accuracy: 0.9322\n",
            "Epoch 59/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.3743 - val_accuracy: 0.9349\n",
            "Epoch 60/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.3323 - val_accuracy: 0.9349\n",
            "Epoch 61/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.4490 - val_accuracy: 0.9212\n",
            "Epoch 62/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0767 - accuracy: 0.9808 - val_loss: 0.4174 - val_accuracy: 0.9303\n",
            "Epoch 63/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0776 - accuracy: 0.9779 - val_loss: 0.3350 - val_accuracy: 0.9423\n",
            "Epoch 64/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.3759 - val_accuracy: 0.9230\n",
            "Epoch 65/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0499 - accuracy: 0.9864 - val_loss: 0.3338 - val_accuracy: 0.9358\n",
            "Epoch 66/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0473 - accuracy: 0.9879 - val_loss: 0.2926 - val_accuracy: 0.9303\n",
            "Epoch 67/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0639 - accuracy: 0.9837 - val_loss: 0.3206 - val_accuracy: 0.9322\n",
            "Epoch 68/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.3250 - val_accuracy: 0.9386\n",
            "Epoch 69/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0486 - accuracy: 0.9872 - val_loss: 0.3110 - val_accuracy: 0.9294\n",
            "Epoch 70/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.3599 - val_accuracy: 0.9294\n",
            "Epoch 71/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0513 - accuracy: 0.9856 - val_loss: 0.3651 - val_accuracy: 0.9322\n",
            "Epoch 72/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.4748 - val_accuracy: 0.9258\n",
            "Epoch 73/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0540 - accuracy: 0.9864 - val_loss: 0.3088 - val_accuracy: 0.9340\n",
            "Epoch 74/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.3289 - val_accuracy: 0.9386\n",
            "Epoch 75/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.3621 - val_accuracy: 0.9386\n",
            "Epoch 76/100\n",
            "103/103 [==============================] - 14s 132ms/step - loss: 0.0549 - accuracy: 0.9866 - val_loss: 0.2720 - val_accuracy: 0.9368\n",
            "Epoch 77/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0702 - accuracy: 0.9821 - val_loss: 0.4047 - val_accuracy: 0.9267\n",
            "Epoch 78/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.2757 - val_accuracy: 0.9441\n",
            "Epoch 79/100\n",
            "103/103 [==============================] - 14s 137ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.2985 - val_accuracy: 0.9395\n",
            "Epoch 80/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.3970 - val_accuracy: 0.9313\n",
            "Epoch 81/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.3307 - val_accuracy: 0.9358\n",
            "Epoch 82/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0561 - accuracy: 0.9867 - val_loss: 0.4534 - val_accuracy: 0.9120\n",
            "Epoch 83/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0663 - accuracy: 0.9827 - val_loss: 0.4477 - val_accuracy: 0.9193\n",
            "Epoch 84/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0925 - accuracy: 0.9782 - val_loss: 0.3428 - val_accuracy: 0.9303\n",
            "Epoch 85/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0434 - accuracy: 0.9881 - val_loss: 0.3214 - val_accuracy: 0.9395\n",
            "Epoch 86/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0672 - accuracy: 0.9838 - val_loss: 0.3082 - val_accuracy: 0.9349\n",
            "Epoch 87/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 0.3673 - val_accuracy: 0.9368\n",
            "Epoch 88/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0442 - accuracy: 0.9907 - val_loss: 0.4671 - val_accuracy: 0.9285\n",
            "Epoch 89/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.3642 - val_accuracy: 0.9413\n",
            "Epoch 90/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.4336 - val_accuracy: 0.9377\n",
            "Epoch 91/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 0.4078 - val_accuracy: 0.9404\n",
            "Epoch 92/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0421 - accuracy: 0.9902 - val_loss: 0.3444 - val_accuracy: 0.9441\n",
            "Epoch 93/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0420 - accuracy: 0.9914 - val_loss: 0.3939 - val_accuracy: 0.9285\n",
            "Epoch 94/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0573 - accuracy: 0.9853 - val_loss: 0.3741 - val_accuracy: 0.9340\n",
            "Epoch 95/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0571 - accuracy: 0.9844 - val_loss: 0.3983 - val_accuracy: 0.9322\n",
            "Epoch 96/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.5451 - val_accuracy: 0.9157\n",
            "Epoch 97/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0772 - accuracy: 0.9824 - val_loss: 0.4319 - val_accuracy: 0.9230\n",
            "Epoch 98/100\n",
            "103/103 [==============================] - 14s 134ms/step - loss: 0.0587 - accuracy: 0.9856 - val_loss: 0.3491 - val_accuracy: 0.9322\n",
            "Epoch 99/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.3702 - val_accuracy: 0.9487\n",
            "Epoch 100/100\n",
            "103/103 [==============================] - 14s 133ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.3990 - val_accuracy: 0.9404\n",
            "Loss: 0.3323105573654175, Accuracy: 0.9459707140922546\n"
          ]
        }
      ]
    }
  ]
}